{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c241ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "function Franke(x,y)\n",
    "    p1 = 3/4*ℯ^(-(9x-2)^2/4-(9y-2)^2/4)\n",
    "    p2 = 3/4*ℯ^(-(9x+1)^2/49-(9y+1)^2/10)\n",
    "    p3 = 1/2*ℯ^(-(9x-7)^2/4-(9y-3)^2/4)\n",
    "    p4 = -1/5*ℯ^(-(9x-4)^2-(9y-7)^2)\n",
    "    return p1+p2+p3+p4\n",
    "end\n",
    "\"\"\"\n",
    "    SplitData2D(xData, yData, zData, train_size)\n",
    "\n",
    "Splits data with given split: train_size\n",
    "\n",
    "\n",
    "# Input\n",
    " - xData::Array:        Data in X  \n",
    " - yData::Array:        Data in Y\n",
    " - zData::Array:        Data in Z\n",
    " - train_size::Float64: Proportion of data to be given as trainingdata\n",
    "\n",
    "\"\"\"\n",
    "function SplitData2D(xData::Array, yData::Array, zData::Array, train_size::Float64)\n",
    "    # Assumes xData and yData are vectors, and zData is a matrix representing the grid\n",
    "\n",
    "    # Flatten the Z matrix and corresponding X, Y arrays\n",
    "    xGrid = repeat(xData, inner=length(yData))\n",
    "    yGrid = repeat(yData, outer=length(xData))\n",
    "    zVector = vec(zData)\n",
    "\n",
    "    # Number of total samples\n",
    "    N = length(zVector)\n",
    "    \n",
    "    # Determine number of training samples\n",
    "    NumTrain = Int(round(N * train_size))\n",
    "    \n",
    "    # Randomly sample indices for training data\n",
    "    train_indices = sample(1:N, NumTrain; replace=false)\n",
    "    \n",
    "    # Determine the test indices\n",
    "    all_indices = collect(1:N)\n",
    "    test_indices = [i for i in all_indices if i ∉ train_indices]\n",
    "    \n",
    "    # Create training and testing datasets\n",
    "    xTrain = xGrid[train_indices]\n",
    "    yTrain = yGrid[train_indices]\n",
    "    zTrain = zVector[train_indices]\n",
    "    \n",
    "    xTest = xGrid[test_indices]\n",
    "    yTest = yGrid[test_indices]\n",
    "    zTest = zVector[test_indices]\n",
    "    \n",
    "    return xTrain, yTrain, zTrain, xTest, yTest, zTest\n",
    "end\n",
    "\"\"\"\n",
    "    DataProjector(x, y, z, numDegrees;train, normalize)\n",
    "\n",
    "This function Projects the Data from the type we generate to the type we need for Regression.\n",
    "\n",
    "\n",
    "# Input\n",
    " - x:        Data in X  \n",
    " - y:        Data in Y\n",
    " - z:        Data in Z\n",
    " - numDegrees: The number of orders of the polynomial\n",
    " - train: Whether or not the data should be handeled as training data\n",
    " - normalize: Whether or not the DesignMatrix should be normalized\n",
    "\"\"\"\n",
    "function DataProjector(x, y, z, numDegrees;train=true, normalize=false)\n",
    "\n",
    "    if !train\n",
    "        #We flatten the data\n",
    "        numSamples = length(x)*length(y)\n",
    "        xData = repeat(x, inner=length(y))  # Repeat xData \n",
    "        yData = repeat(y, outer=length(x))  # Repeat yData \n",
    "        zData = vec(z) #Flattened Z data\n",
    "    else\n",
    "        numSamples = length(z)\n",
    "        xData=x\n",
    "        yData=y\n",
    "        zData=z\n",
    "    end\n",
    "     #NxN\n",
    "    numFeatures = (numDegrees + 1) * (numDegrees + 2) ÷ 2  # Number of polynomial terms\n",
    "    DesignMatrix = zeros(numSamples, numFeatures)\n",
    "    column=1\n",
    "    for i in 0:numDegrees\n",
    "        for j in 0:(numDegrees-i)\n",
    "            DesignMatrix[:,column] .= (xData .^ i) .* (yData .^ j)\n",
    "            column+=1\n",
    "        end\n",
    "    end\n",
    "    if normalize\n",
    "        col_std = zeros(column-1)\n",
    "        col_mean = zeros(column-1)\n",
    "        for j in 1:(column-1)\n",
    "            col_mean[j] = mean(DesignMatrix[:, j])\n",
    "            col_std[j] = std(DesignMatrix[:, j])\n",
    "\n",
    "            # Avoid dividing by zero if the standard deviation is zero (constant column)\n",
    "            if col_std[j] != 0\n",
    "                DesignMatrix[:, j] = (DesignMatrix[:, j] .- col_mean[j]) ./ col_std[j]\n",
    "            else\n",
    "                DesignMatrix[:, j] = DesignMatrix[:, j]  # No standardization if std is 0\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    if train\n",
    "        if !normalize\n",
    "            return DesignMatrix\n",
    "        else\n",
    "            return DesignMatrix, col_std, col_mean\n",
    "        end\n",
    "    else\n",
    "        if !normalize\n",
    "            return DesignMatrix, zData\n",
    "        else\n",
    "            return DesignMatrix, zData, col_std, col_mean\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "function LassoReg(DesignMatrix, zData, γ)\n",
    "    (T, K) = (size(DesignMatrix, 1), size(DesignMatrix, 2))\n",
    "    Q = DesignMatrix'DesignMatrix #/ T\n",
    "    c = DesignMatrix'zData #/ T                      #c'b = Y'X*b\n",
    "\n",
    "    b = Variable(K)              #define variables to optimize over\n",
    "    L1 = quadform(b, Q)            #b'Q*b\n",
    "    L2 = dot(c, b)                 #c'b\n",
    "    L3 = norm(b, 1)                #sum(|b|)\n",
    "\n",
    "    # u'u/T + γ*sum(|b|) where u = Y-Xb\n",
    "    problem = minimize(L1 - 2 * L2 + γ * L3)\n",
    "\n",
    "    solve!(problem, SCS.Optimizer; silent = true)\n",
    "    problem.status == Convex.MOI.OPTIMAL ? beta = vec(Convex.evaluate(b)) : beta = NaN\n",
    "\n",
    "    return beta\n",
    "end\n",
    "\"\"\"\n",
    "    Regression(DesignMatrix, zData, Method; λ)\n",
    "\n",
    "Preforms a Regression with a DesignMatrix, zData and a given method\n",
    "\n",
    "\n",
    "# Input\n",
    " - DesignMatrix: The designmatrix for the regression\n",
    " - zData:        The z data for the regression\n",
    " - Method:       The method, either; OLS, Ridge or Lasso\n",
    " - λ:            Parameter for Ridge and Lasso regression\n",
    "\"\"\"\n",
    "function Regression(DesignMatrix, zData, Method; λ=0)\n",
    "    if Method==\"OLS\"\n",
    "        Hessian = Transpose(DesignMatrix)*DesignMatrix\n",
    "        beta = inv(Hessian)*Transpose(DesignMatrix)*zData\n",
    "        \n",
    "    elseif Method==\"Ridge\"\n",
    "        Hessian = Transpose(DesignMatrix)*DesignMatrix\n",
    "        beta = inv(Hessian+λ*I)*Transpose(DesignMatrix)*zData\n",
    "        \n",
    "    elseif Method==\"Lasso\"\n",
    "        beta = LassoReg(DesignMatrix, zData, λ)\n",
    "        \n",
    "    else\n",
    "        @warn \"Method Undefined\" \n",
    "        println(\"Expected: OLS, Lasso or Ridge, but got: \", Method)\n",
    "        return\n",
    "    end\n",
    "    return beta\n",
    "end\n",
    "\n",
    "function MSE(DesignMatrix, z, beta; λ=0, γ=0)\n",
    "    N = length(z)\n",
    "    MSE = 1/N*sum((z .- DesignMatrix*beta).^2)+λ*(Transpose(beta)*beta) + γ*sum(abs.(beta))\n",
    "    return MSE\n",
    "end\n",
    "\n",
    "function R2(DesignMatrix, zData, beta)\n",
    "    N = length(zData)\n",
    "    z_avg = 1/N*sum(zData)\n",
    "    R2 = 1- sum((zData.-DesignMatrix*beta).^2)/sum((zData .- z_avg).^2)\n",
    "    return R2\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
